{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "596d0ffb-c7f4-4c6a-a586-b42a576ce37b",
   "metadata": {},
   "source": [
    "# NLP and Reddit Subcommunities - Modeling\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878f7860-91f9-4598-98ab-a3a8dc52c80c",
   "metadata": {},
   "source": [
    "In this notebook, our objective is to build models that can accurately classify the subreddit from which a given post originates. To achieve this, we will employ pipelines, grid-searching (GridSearchCV) and randomized-searching (RandomizedSearchCV), and iterating through different hyperparameters to evaluate the performance of various machine learning algorithms. Our focus will be on testing classification models such as Logistic Regression, Multinomial Naive Bayes, and Support Vector Machines. Additionally, we will address the challenges of overfitting or underfitting by considering approaches like Random Forest or Gradient Boosting, respectively. \n",
    "\n",
    "For more information on the data pulling and initial data cleaning, see the [initial notebook](./code/01_PRAW_Data_Acquisition_Initial_Cleaning.ipynb) of this analysis. For data exploration, further cleaning, and visualization, see the [second notebook](./02_EDA_and_Cleaning) of this analysis.\n",
    "\n",
    "For more information on the background, a summary of methods, and findings, please see the associated [README](./README.md) for this analysis.\n",
    "\n",
    "### Contents:\n",
    "- [I. Baseline and Pre-Processing Functions](#I.-Baseline-and-Pre-Processing-Functions)\n",
    "- [II. Model-Building and Testing](#II.-Model-Building-and-Testing)\n",
    "    - [Pipelines and GridSearch / RandomizedSearch](#Pipelines-and-GridSearch-/-RandomizedSearch)\n",
    "        - [Model 1: Logistic Regression](#Model-1:-Logistic-Regression)\n",
    "        - [Model 2: Multinomial Naive Bayes](#Model-2:-Multinomial-Naive-Bayes)\n",
    "        - [Model 3: Support Vector Machine](#Model-3:-Support-Vector-Machine)\n",
    "    - [Ensembling](#Ensembling)\n",
    "    - [Reducing Overfitting](#Reducing-Overfitting)\n",
    "        - [Model 4: Random Forest and ExtraTrees](#Model-4:-Random-Forest-and-ExtraTrees)\n",
    "- [III. Model Summarization](#II.-Model-Summarization)\n",
    "- [IV. Final Model](#III.-Final-Model)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "297df2bd-6f08-4b31-90d5-da1d78caf63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "# Notebook was run with warnings enabled and any significant ones were addressed, remaining warnings are insignificant and \n",
    " # have been suppressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c48f2112-dd49-4d66-bd5d-91f13511d611",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report, RocCurveDisplay, roc_auc_score\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn import datasets\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, BaggingClassifier, VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c71b8cac-022c-42d3-b0e0-9ce0743fb63a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_utc</th>\n",
       "      <th>author</th>\n",
       "      <th>score</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>text</th>\n",
       "      <th>lem_text</th>\n",
       "      <th>stem_text</th>\n",
       "      <th>post_length</th>\n",
       "      <th>post_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.686844e+09</td>\n",
       "      <td>bas1cred</td>\n",
       "      <td>26</td>\n",
       "      <td>0.91</td>\n",
       "      <td>19</td>\n",
       "      <td>snowboardingnoobs</td>\n",
       "      <td>my first board. ready for the upcoming season!!</td>\n",
       "      <td>my first board ready for the upcoming season</td>\n",
       "      <td>my first board readi for the upcom season</td>\n",
       "      <td>48</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.686786e+09</td>\n",
       "      <td>Pooffios</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>12</td>\n",
       "      <td>snowboardingnoobs</td>\n",
       "      <td>outer side foot pain hi all, i was hoping to g...</td>\n",
       "      <td>outer side foot pain hi all i wa hoping to get...</td>\n",
       "      <td>outer side foot pain hi all i wa hope to get s...</td>\n",
       "      <td>301</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.686781e+09</td>\n",
       "      <td>trips69420</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>15</td>\n",
       "      <td>snowboardingnoobs</td>\n",
       "      <td>first board? looking to probably grab this as ...</td>\n",
       "      <td>first board looking to probably grab this a my...</td>\n",
       "      <td>first board look to probabl grab thi as my fir...</td>\n",
       "      <td>274</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.686779e+09</td>\n",
       "      <td>twinbee</td>\n",
       "      <td>11</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0</td>\n",
       "      <td>snowboardingnoobs</td>\n",
       "      <td>i did a front-side 180 today! more than one in...</td>\n",
       "      <td>i did a front side 180 today more than one in ...</td>\n",
       "      <td>i did a front side 180 today more than one in ...</td>\n",
       "      <td>1565</td>\n",
       "      <td>289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.686767e+09</td>\n",
       "      <td>Madden_Stephen</td>\n",
       "      <td>2</td>\n",
       "      <td>0.67</td>\n",
       "      <td>24</td>\n",
       "      <td>snowboardingnoobs</td>\n",
       "      <td>step-on boot recommendation? i’ve done a decen...</td>\n",
       "      <td>step on boot recommendation i ve done a decent...</td>\n",
       "      <td>step on boot recommend i ve done a decent bit ...</td>\n",
       "      <td>686</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    created_utc          author  score  upvote_ratio  num_comments  \\\n",
       "0  1.686844e+09        bas1cred     26          0.91            19   \n",
       "1  1.686786e+09        Pooffios      3          1.00            12   \n",
       "2  1.686781e+09      trips69420      2          0.75            15   \n",
       "3  1.686779e+09         twinbee     11          0.87             0   \n",
       "4  1.686767e+09  Madden_Stephen      2          0.67            24   \n",
       "\n",
       "           subreddit                                               text  \\\n",
       "0  snowboardingnoobs   my first board. ready for the upcoming season!!    \n",
       "1  snowboardingnoobs  outer side foot pain hi all, i was hoping to g...   \n",
       "2  snowboardingnoobs  first board? looking to probably grab this as ...   \n",
       "3  snowboardingnoobs  i did a front-side 180 today! more than one in...   \n",
       "4  snowboardingnoobs  step-on boot recommendation? i’ve done a decen...   \n",
       "\n",
       "                                            lem_text  \\\n",
       "0       my first board ready for the upcoming season   \n",
       "1  outer side foot pain hi all i wa hoping to get...   \n",
       "2  first board looking to probably grab this a my...   \n",
       "3  i did a front side 180 today more than one in ...   \n",
       "4  step on boot recommendation i ve done a decent...   \n",
       "\n",
       "                                           stem_text  post_length  \\\n",
       "0          my first board readi for the upcom season           48   \n",
       "1  outer side foot pain hi all i wa hope to get s...          301   \n",
       "2  first board look to probabl grab thi as my fir...          274   \n",
       "3  i did a front side 180 today more than one in ...         1565   \n",
       "4  step on boot recommend i ve done a decent bit ...          686   \n",
       "\n",
       "   post_word_count  \n",
       "0                8  \n",
       "1               60  \n",
       "2               53  \n",
       "3              289  \n",
       "4              122  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowski = pd.read_csv('../data/Clean/snow_ski2.csv')\n",
    "snowski.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30740e2e-b375-48d9-a5f7-ca496c2118c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## I. Baseline and Pre-Processing Functions\n",
    "##### Please note: \n",
    "- ##### Lemmatizing and Stemming functions were generated and tested, but not all are used as final parameters in any of our models. The models were also run using \"lem_text\" and \"stem_text\" as target variables directly, but did not have any impact. \n",
    "- ##### A list of custom stop words was created to assist our model in identifying the subreddit from which a post originated (e.g., snowboard, snowboarding, ski, skiing). These custom words were tested as stop words in our models, but were ultimately excluded from further consideration. Introducing this additional complexity to our model is unnecessary and not aligned with our problem statement. The code for incorporating these custom stop words has been commented out below.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "298e0599-3b3e-4075-8eff-37d69092b5f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "skiing               0.51242\n",
       "snowboardingnoobs    0.48758\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define baseline\n",
    "snowski.subreddit.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f19874-e0e4-4fd2-befe-cec381ff3796",
   "metadata": {},
   "source": [
    "##### <span style = 'color:blue'> Our model must have an accuracy score > 51.2% to be useful.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8c48eb3-b3d6-49e5-b388-9efea837d0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "snowski['subreddit'] = snowski['subreddit'].map({'snowboardingnoobs': 1, 'skiing': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d8c3d80-13b8-4502-9eee-709e175b5598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for Lemmatizing\n",
    "def lemmatize_txt(text):\n",
    "    \n",
    "    tokenizer = RegexpTokenizer('\\w+')\n",
    "    split_txt = tokenizer.tokenize(text)\n",
    "\n",
    "    # Instantiate lemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "        \n",
    "    # Lemmatize and Rejoin\n",
    "    return ' '.join([lemmatizer.lemmatize(word) for word in split_txt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8c689b2-7de9-4fa1-bab9-f41c6a8e57d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for Stemming\n",
    "def stem_txt(text):\n",
    "    \n",
    "    tokenizer = RegexpTokenizer('\\w+')\n",
    "    split_txt = tokenizer.tokenize(text)\n",
    "\n",
    "    # Instantiate Stemmer\n",
    "    p_stemmer = PorterStemmer()\n",
    "\n",
    "    # Stem and Rejoin\n",
    "    return ' '.join([p_stemmer.stem(word) for word in split_txt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3d58f4a-af3f-4642-88ed-9b6f0fe33f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and save custom stopwords\n",
    "\n",
    "# english_stopwords = CountVectorizer(stop_words='english').get_stop_words() # source: https://scikit-learn-ts-git-feature-docs-2-saasify.vercel.app/docs/classes/CountVectorizer\n",
    "# custom_words = ['snowboard', 'snowboarding', 'board', 'ski', 'skier', 'skiing', 'skis', 'just', 'like', 'wa', 'http', 'https', 'www', 'reddit', 'subreddit']\n",
    "# custom_words = list(english_stopwords) + custom_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d431b26d-a73c-4635-820f-4d5da1097192",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = snowski['text']\n",
    "y = snowski['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0aa70b5-0d7c-4394-a412-eed5aadef0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 1527) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8134c2-8ceb-4f99-b9d4-bb220895b4fb",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## II. Model-Building and Testing\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20568acf-4545-4f63-9693-3c32149652ee",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Pipelines and GridSearch / RandomizedSearch\n",
    "\n",
    "##### Please note that the parameter grids used for optimization contained more parameters than those shown below. To improve computational efficiency, only a selection of optimal parameters are included in the grids below, while others were excluded to minimize rerun time and avoid fitting unnecessary models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4f595b-4472-43f4-8816-a796701dfa0b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Model 1: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96e7c5d0-c2d4-4db5-9809-ca7dd92c7245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline that tests b/t CVEC and TVEC transformers and an estimator\n",
    "pipe_log = Pipeline([\n",
    "                 ('vec', None),\n",
    "                 ('logr', LogisticRegression(solver = 'liblinear', max_iter=1000))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fb25869-40a7-45f1-9111-8ad115101fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "pgrid_logr =[\n",
    "    {\n",
    "    'vec': [CountVectorizer()],\n",
    "    'vec__stop_words': [None, 'english'],\n",
    "    'vec__max_features': [7000, 8000], \n",
    "    'vec__min_df': [2, 3],\n",
    "    'vec__max_df': [0.85], #tested 0.8, 0.95 as well\n",
    "    #'vec__preprocessor': [None, lemmatize_txt, stem_txt],\n",
    "    'logr__C': np.linspace(.05,10.0,10),\n",
    "    'logr__penalty': ['l2'] #tested l1, l2 was more optimal\n",
    "    },\n",
    "    {\n",
    "    'vec': [TfidfVectorizer()],\n",
    "    'vec__stop_words': [None, 'english'],\n",
    "    'vec__max_features': [7000, 8000], \n",
    "    'vec__min_df': [2, 3],\n",
    "    'vec__max_df': [0.85],\n",
    "    #'vec__preprocessor': [None, lemmatize_txt, stem_txt],\n",
    "    'logr__C': np.linspace(.05,10.0,10),\n",
    "    'logr__penalty': ['l2']\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c67196af-c9ff-44b3-8ed2-ce8a6ecb22f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.45 s\n",
      "Wall time: 28.9 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;vec&#x27;, None),\n",
       "                                       (&#x27;logr&#x27;,\n",
       "                                        LogisticRegression(max_iter=1000,\n",
       "                                                           solver=&#x27;liblinear&#x27;))]),\n",
       "             n_jobs=10,\n",
       "             param_grid=[{&#x27;logr__C&#x27;: array([ 0.05      ,  1.15555556,  2.26111111,  3.36666667,  4.47222222,\n",
       "        5.57777778,  6.68333333,  7.78888889,  8.89444444, 10.        ]),\n",
       "                          &#x27;logr__penalty&#x27;: [&#x27;l2&#x27;], &#x27;vec&#x27;: [CountVectorizer()],\n",
       "                          &#x27;vec__max_df&#x27;: [0.85],\n",
       "                          &#x27;vec__max_features&#x27;:...\n",
       "                          &#x27;vec__stop_words&#x27;: [None, &#x27;english&#x27;]},\n",
       "                         {&#x27;logr__C&#x27;: array([ 0.05      ,  1.15555556,  2.26111111,  3.36666667,  4.47222222,\n",
       "        5.57777778,  6.68333333,  7.78888889,  8.89444444, 10.        ]),\n",
       "                          &#x27;logr__penalty&#x27;: [&#x27;l2&#x27;],\n",
       "                          &#x27;vec&#x27;: [TfidfVectorizer(max_df=0.85,\n",
       "                                                  max_features=7000, min_df=2,\n",
       "                                                  stop_words=&#x27;english&#x27;)],\n",
       "                          &#x27;vec__max_df&#x27;: [0.85],\n",
       "                          &#x27;vec__max_features&#x27;: [7000, 8000],\n",
       "                          &#x27;vec__min_df&#x27;: [2, 3],\n",
       "                          &#x27;vec__stop_words&#x27;: [None, &#x27;english&#x27;]}])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;vec&#x27;, None),\n",
       "                                       (&#x27;logr&#x27;,\n",
       "                                        LogisticRegression(max_iter=1000,\n",
       "                                                           solver=&#x27;liblinear&#x27;))]),\n",
       "             n_jobs=10,\n",
       "             param_grid=[{&#x27;logr__C&#x27;: array([ 0.05      ,  1.15555556,  2.26111111,  3.36666667,  4.47222222,\n",
       "        5.57777778,  6.68333333,  7.78888889,  8.89444444, 10.        ]),\n",
       "                          &#x27;logr__penalty&#x27;: [&#x27;l2&#x27;], &#x27;vec&#x27;: [CountVectorizer()],\n",
       "                          &#x27;vec__max_df&#x27;: [0.85],\n",
       "                          &#x27;vec__max_features&#x27;:...\n",
       "                          &#x27;vec__stop_words&#x27;: [None, &#x27;english&#x27;]},\n",
       "                         {&#x27;logr__C&#x27;: array([ 0.05      ,  1.15555556,  2.26111111,  3.36666667,  4.47222222,\n",
       "        5.57777778,  6.68333333,  7.78888889,  8.89444444, 10.        ]),\n",
       "                          &#x27;logr__penalty&#x27;: [&#x27;l2&#x27;],\n",
       "                          &#x27;vec&#x27;: [TfidfVectorizer(max_df=0.85,\n",
       "                                                  max_features=7000, min_df=2,\n",
       "                                                  stop_words=&#x27;english&#x27;)],\n",
       "                          &#x27;vec__max_df&#x27;: [0.85],\n",
       "                          &#x27;vec__max_features&#x27;: [7000, 8000],\n",
       "                          &#x27;vec__min_df&#x27;: [2, 3],\n",
       "                          &#x27;vec__stop_words&#x27;: [None, &#x27;english&#x27;]}])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vec&#x27;, None),\n",
       "                (&#x27;logr&#x27;,\n",
       "                 LogisticRegression(max_iter=1000, solver=&#x27;liblinear&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">None</label><div class=\"sk-toggleable__content\"><pre>None</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('vec', None),\n",
       "                                       ('logr',\n",
       "                                        LogisticRegression(max_iter=1000,\n",
       "                                                           solver='liblinear'))]),\n",
       "             n_jobs=10,\n",
       "             param_grid=[{'logr__C': array([ 0.05      ,  1.15555556,  2.26111111,  3.36666667,  4.47222222,\n",
       "        5.57777778,  6.68333333,  7.78888889,  8.89444444, 10.        ]),\n",
       "                          'logr__penalty': ['l2'], 'vec': [CountVectorizer()],\n",
       "                          'vec__max_df': [0.85],\n",
       "                          'vec__max_features':...\n",
       "                          'vec__stop_words': [None, 'english']},\n",
       "                         {'logr__C': array([ 0.05      ,  1.15555556,  2.26111111,  3.36666667,  4.47222222,\n",
       "        5.57777778,  6.68333333,  7.78888889,  8.89444444, 10.        ]),\n",
       "                          'logr__penalty': ['l2'],\n",
       "                          'vec': [TfidfVectorizer(max_df=0.85,\n",
       "                                                  max_features=7000, min_df=2,\n",
       "                                                  stop_words='english')],\n",
       "                          'vec__max_df': [0.85],\n",
       "                          'vec__max_features': [7000, 8000],\n",
       "                          'vec__min_df': [2, 3],\n",
       "                          'vec__stop_words': [None, 'english']}])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Fit model via GridSearch\n",
    "gs_log = GridSearchCV(pipe_log, pgrid_logr, cv=5, n_jobs=10)\n",
    "gs_log.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22fcc0dd-4945-41eb-b108-9219b4fbf158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for Accuracy Report\n",
    "preds_log = gs_log.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "863dc351-e5bc-4420-8a58-52c26b940715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- \u001b[1mLogistic Regression w/ GridSearch\u001b[0m ---------\n",
      "------------------- Train: 0.9532 -------------------\n",
      "------------------- Test: 0.8801 --------------------\n",
      "Best Params: {'logr__C': 2.2611111111111106, 'logr__penalty': 'l2', 'vec': TfidfVectorizer(max_df=0.85, max_features=7000, min_df=2, stop_words='english'), 'vec__max_df': 0.85, 'vec__max_features': 7000, 'vec__min_df': 2, 'vec__stop_words': 'english'}\n"
     ]
    }
   ],
   "source": [
    "b1 = \"\\033[1m\"\n",
    "b0 = \"\\033[0m\"\n",
    "\n",
    "print(f'--------- {b1}Logistic Regression w/ GridSearch{b0} ---------') # source: https://stackoverflow.com/questions/8924173/how-can-i-print-bold-text-in-python\n",
    "print(f'------------------- Train: {round(gs_log.score(X_train, y_train),4)} -------------------')\n",
    "print(f'------------------- Test: {round(gs_log.score(X_test, y_test),4)} --------------------')\n",
    "print('Best Params:', gs_log.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b12cca3f-1af4-4239-b23b-b919971021ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 449 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[(&#x27;vec&#x27;, None),\n",
       "                                             (&#x27;logr&#x27;,\n",
       "                                              LogisticRegression(max_iter=1000,\n",
       "                                                                 solver=&#x27;liblinear&#x27;))]),\n",
       "                   n_jobs=10,\n",
       "                   param_distributions=[{&#x27;logr__C&#x27;: [5.577777777777777],\n",
       "                                         &#x27;logr__penalty&#x27;: [&#x27;l2&#x27;],\n",
       "                                         &#x27;vec&#x27;: [TfidfVectorizer(max_df=0.85,\n",
       "                                                                 max_features=8000,\n",
       "                                                                 min_df=2)],\n",
       "                                         &#x27;vec__max_df&#x27;: [0.85],\n",
       "                                         &#x27;vec__max_features&#x27;: [8000],\n",
       "                                         &#x27;vec__min_df&#x27;: [2],\n",
       "                                         &#x27;vec__stop_words&#x27;: [None]}],\n",
       "                   random_state=111)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[(&#x27;vec&#x27;, None),\n",
       "                                             (&#x27;logr&#x27;,\n",
       "                                              LogisticRegression(max_iter=1000,\n",
       "                                                                 solver=&#x27;liblinear&#x27;))]),\n",
       "                   n_jobs=10,\n",
       "                   param_distributions=[{&#x27;logr__C&#x27;: [5.577777777777777],\n",
       "                                         &#x27;logr__penalty&#x27;: [&#x27;l2&#x27;],\n",
       "                                         &#x27;vec&#x27;: [TfidfVectorizer(max_df=0.85,\n",
       "                                                                 max_features=8000,\n",
       "                                                                 min_df=2)],\n",
       "                                         &#x27;vec__max_df&#x27;: [0.85],\n",
       "                                         &#x27;vec__max_features&#x27;: [8000],\n",
       "                                         &#x27;vec__min_df&#x27;: [2],\n",
       "                                         &#x27;vec__stop_words&#x27;: [None]}],\n",
       "                   random_state=111)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vec&#x27;, None),\n",
       "                (&#x27;logr&#x27;,\n",
       "                 LogisticRegression(max_iter=1000, solver=&#x27;liblinear&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">None</label><div class=\"sk-toggleable__content\"><pre>None</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('vec', None),\n",
       "                                             ('logr',\n",
       "                                              LogisticRegression(max_iter=1000,\n",
       "                                                                 solver='liblinear'))]),\n",
       "                   n_jobs=10,\n",
       "                   param_distributions=[{'logr__C': [5.577777777777777],\n",
       "                                         'logr__penalty': ['l2'],\n",
       "                                         'vec': [TfidfVectorizer(max_df=0.85,\n",
       "                                                                 max_features=8000,\n",
       "                                                                 min_df=2)],\n",
       "                                         'vec__max_df': [0.85],\n",
       "                                         'vec__max_features': [8000],\n",
       "                                         'vec__min_df': [2],\n",
       "                                         'vec__stop_words': [None]}],\n",
       "                   random_state=111)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# The following optimized hyperparameters were observed during one of our RandomizedSearches, and are being applied here\n",
    "pgrid_logr_best =[\n",
    "    {\n",
    "    'vec': [TfidfVectorizer()],\n",
    "    'vec__stop_words': [None],\n",
    "    'vec__max_features': [8000], \n",
    "    'vec__min_df': [2],\n",
    "    'vec__max_df': [0.85],\n",
    "    'logr__C': [5.577777777777777],\n",
    "    'logr__penalty': ['l2']\n",
    "    }\n",
    "]\n",
    "\n",
    "# Test RandomizedSearch for comparison in timing and outcome\n",
    "rs_log = RandomizedSearchCV(pipe_log, pgrid_logr_best, cv=5, n_iter=10, n_jobs=10, random_state=111)\n",
    "rs_log.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b91019ae-cea3-452a-a6ca-ff5199a8f14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_log_r = rs_log.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ada2941-e56e-40d1-bba5-501b3b1805f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ \u001b[1mLogistic Regression w/ RandomizedSearch\u001b[0m ------\n",
      "------------------- Train: 0.9728 -------------------\n",
      "------------------- Test: 0.8836 --------------------\n",
      "Best Params: {'vec__stop_words': None, 'vec__min_df': 2, 'vec__max_features': 8000, 'vec__max_df': 0.85, 'vec': TfidfVectorizer(max_df=0.85, max_features=8000, min_df=2), 'logr__penalty': 'l2', 'logr__C': 5.577777777777777}\n"
     ]
    }
   ],
   "source": [
    "print(f'------ {b1}Logistic Regression w/ RandomizedSearch{b0} ------')\n",
    "print(f'------------------- Train: {round(rs_log.score(X_train, y_train),4)} -------------------')\n",
    "print(f'------------------- Test: {round(rs_log.score(X_test, y_test),4)} --------------------')\n",
    "print('Best Params:', rs_log.best_params_)\n",
    "\n",
    "# Randomized search computed faster and test score is slightly better - we will utilize RS more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "410df91a-1d9f-4c91-bf02-6a04c0b9f95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code below was run with every rerun of this notebook and metrics were observed, commenting out to save computational power\n",
    "\n",
    "#%%time \n",
    "# RandomizedSearch gives a slightly different testing score and parameters each run (when done without random_state), I want to see the average and SD over 30 runs to make sure random \n",
    "    # parameters chosen from single run are reprsentative\n",
    "#num_runs = 35  # Number of runs\n",
    "#results = []\n",
    "\n",
    "#for i in range(num_runs):\n",
    "    #rs_log = RandomizedSearchCV(pipe_log, pgrid_logr, cv=5, n_iter=10, n_jobs=10)\n",
    "    #rs_log.fit(X_train, y_train)\n",
    "    #results.append(rs_log.score(X_test, y_test))\n",
    "    \n",
    "#scr = sum(results) / len(results)\n",
    "#scr_sd = (sum((i - scr)**2 for i in results) / len(results))**0.5\n",
    "#lcl = scr - 1.96*scr_sd\n",
    "#ucl = scr + 1.96*scr_sd\n",
    "\n",
    "#print(f'MEAN: {round(scr,4)}')\n",
    "#print(f'SD: {round(scr_sd,4)}')\n",
    "#print(f'95% CI: ({round(lcl,4)}, {round(ucl,4)})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d02cb899-4203-4f3c-9961-0a248c27b38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomSearch is not an exhaustive search within the predefined parameters grid, it randomly samples combinations,\n",
    "    # providing a more efficient exploration of the hyperparameter space. Each run of RandomSearch will give a different\n",
    "    # combination and therefore a slightly different training and testing accuracy score, sometimes even a better score than\n",
    "    # when using GridSearch. We will choose whichever had the higher score between the two.\n",
    "    \n",
    "final_log_score = max(gs_log.score(X_test, y_test), rs_log.score(X_test, y_test))\n",
    "if (gs_log.score(X_test, y_test)) > (rs_log.score(X_test, y_test)):\n",
    "    final_log_preds = preds_log\n",
    "else:\n",
    "    final_log_preds = preds_log_r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120baa5f-cb6e-490e-a79a-a2e5fe1a13fd",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "#### Model 2: Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "48edf2a8-2b93-405c-a6b9-1c3abbd4eada",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_nb = Pipeline([\n",
    "    ('vec', None),\n",
    "    ('nb', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a1e72b5-002d-4e33-8e37-0de2147eb3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pgrid_nb =[\n",
    "    {\n",
    "    'vec': [CountVectorizer()],\n",
    "    'vec__stop_words': [None, 'english'],\n",
    "    'vec__max_features': [7000, 8000], \n",
    "    'vec__min_df': [2, 3],\n",
    "    'vec__max_df': [0.80, 0.90],\n",
    "    #'vec__preprocessor': [None, lemmatize_txt, stem_txt],\n",
    "    'nb__alpha': [.01, 0.5, 1.0, 5.0]\n",
    "    },\n",
    "    {\n",
    "    'vec': [TfidfVectorizer()],\n",
    "    'vec__stop_words': [None, 'english'],\n",
    "    'vec__max_features': [7000, 8000], \n",
    "    'vec__min_df': [2, 3],\n",
    "    'vec__max_df': [0.80, 0.90],\n",
    "    #'vec__preprocessor': [None, lemmatize_txt, stem_txt],\n",
    "    'nb__alpha': [.01, 0.5, 1.0, 5.0]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "37b7044a-0832-4ec9-b8b4-010b33f2e80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 688 ms\n",
      "Wall time: 32.4 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;vec&#x27;, None), (&#x27;nb&#x27;, MultinomialNB())]),\n",
       "             n_jobs=5,\n",
       "             param_grid=[{&#x27;nb__alpha&#x27;: [0.01, 0.5, 1.0, 5.0],\n",
       "                          &#x27;vec&#x27;: [CountVectorizer()], &#x27;vec__max_df&#x27;: [0.8, 0.9],\n",
       "                          &#x27;vec__max_features&#x27;: [7000, 8000],\n",
       "                          &#x27;vec__min_df&#x27;: [2, 3],\n",
       "                          &#x27;vec__stop_words&#x27;: [None, &#x27;english&#x27;]},\n",
       "                         {&#x27;nb__alpha&#x27;: [0.01, 0.5, 1.0, 5.0],\n",
       "                          &#x27;vec&#x27;: [TfidfVectorizer(max_df=0.8, max_features=7000,\n",
       "                                                  min_df=3,\n",
       "                                                  stop_words=&#x27;english&#x27;)],\n",
       "                          &#x27;vec__max_df&#x27;: [0.8, 0.9],\n",
       "                          &#x27;vec__max_features&#x27;: [7000, 8000],\n",
       "                          &#x27;vec__min_df&#x27;: [2, 3],\n",
       "                          &#x27;vec__stop_words&#x27;: [None, &#x27;english&#x27;]}])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;vec&#x27;, None), (&#x27;nb&#x27;, MultinomialNB())]),\n",
       "             n_jobs=5,\n",
       "             param_grid=[{&#x27;nb__alpha&#x27;: [0.01, 0.5, 1.0, 5.0],\n",
       "                          &#x27;vec&#x27;: [CountVectorizer()], &#x27;vec__max_df&#x27;: [0.8, 0.9],\n",
       "                          &#x27;vec__max_features&#x27;: [7000, 8000],\n",
       "                          &#x27;vec__min_df&#x27;: [2, 3],\n",
       "                          &#x27;vec__stop_words&#x27;: [None, &#x27;english&#x27;]},\n",
       "                         {&#x27;nb__alpha&#x27;: [0.01, 0.5, 1.0, 5.0],\n",
       "                          &#x27;vec&#x27;: [TfidfVectorizer(max_df=0.8, max_features=7000,\n",
       "                                                  min_df=3,\n",
       "                                                  stop_words=&#x27;english&#x27;)],\n",
       "                          &#x27;vec__max_df&#x27;: [0.8, 0.9],\n",
       "                          &#x27;vec__max_features&#x27;: [7000, 8000],\n",
       "                          &#x27;vec__min_df&#x27;: [2, 3],\n",
       "                          &#x27;vec__stop_words&#x27;: [None, &#x27;english&#x27;]}])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vec&#x27;, None), (&#x27;nb&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">None</label><div class=\"sk-toggleable__content\"><pre>None</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('vec', None), ('nb', MultinomialNB())]),\n",
       "             n_jobs=5,\n",
       "             param_grid=[{'nb__alpha': [0.01, 0.5, 1.0, 5.0],\n",
       "                          'vec': [CountVectorizer()], 'vec__max_df': [0.8, 0.9],\n",
       "                          'vec__max_features': [7000, 8000],\n",
       "                          'vec__min_df': [2, 3],\n",
       "                          'vec__stop_words': [None, 'english']},\n",
       "                         {'nb__alpha': [0.01, 0.5, 1.0, 5.0],\n",
       "                          'vec': [TfidfVectorizer(max_df=0.8, max_features=7000,\n",
       "                                                  min_df=3,\n",
       "                                                  stop_words='english')],\n",
       "                          'vec__max_df': [0.8, 0.9],\n",
       "                          'vec__max_features': [7000, 8000],\n",
       "                          'vec__min_df': [2, 3],\n",
       "                          'vec__stop_words': [None, 'english']}])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "gs_nb = GridSearchCV(pipe_nb, pgrid_nb, cv=5, n_jobs=5)\n",
    "gs_nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7430dd01-e13f-40f2-beba-17ce22ca5c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for Accuracy Report\n",
    "preds_nb = gs_nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2b15b05b-7a96-49f2-a431-4dc767e653b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- \u001b[1mMultinomial Bayes w/ GridSearch\u001b[0m ----------\n",
      "------------------- Train: 0.8905 -------------------\n",
      "------------------- Test: 0.8566 --------------------\n",
      "Best Params: {'nb__alpha': 5.0, 'vec': TfidfVectorizer(max_df=0.8, max_features=7000, min_df=3, stop_words='english'), 'vec__max_df': 0.8, 'vec__max_features': 7000, 'vec__min_df': 3, 'vec__stop_words': 'english'}\n"
     ]
    }
   ],
   "source": [
    "print(f'---------- {b1}Multinomial Bayes w/ GridSearch{b0} ----------')\n",
    "print(f'------------------- Train: {round(gs_nb.score(X_train, y_train),4)} -------------------')\n",
    "print(f'------------------- Test: {round(gs_nb.score(X_test, y_test),4)} --------------------')\n",
    "print('Best Params:', gs_nb.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "36460329-26b8-4ab1-8cce-e54d7bba1a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 234 ms\n",
      "Wall time: 2.31 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[(&#x27;vec&#x27;, None),\n",
       "                                             (&#x27;nb&#x27;, MultinomialNB())]),\n",
       "                   n_jobs=5,\n",
       "                   param_distributions=[{&#x27;nb__alpha&#x27;: [0.01, 0.5, 1.0, 5.0],\n",
       "                                         &#x27;vec&#x27;: [CountVectorizer(max_df=0.8,\n",
       "                                                                 max_features=7000,\n",
       "                                                                 min_df=3,\n",
       "                                                                 stop_words=&#x27;english&#x27;)],\n",
       "                                         &#x27;vec__max_df&#x27;: [0.8, 0.9],\n",
       "                                         &#x27;vec__max_features&#x27;: [7000, 8000],\n",
       "                                         &#x27;vec__min_df&#x27;: [2, 3],\n",
       "                                         &#x27;vec__stop_words&#x27;: [None, &#x27;english&#x27;]},\n",
       "                                        {&#x27;nb__alpha&#x27;: [0.01, 0.5, 1.0, 5.0],\n",
       "                                         &#x27;vec&#x27;: [TfidfVectorizer(max_df=0.8,\n",
       "                                                                 max_features=7000,\n",
       "                                                                 min_df=3,\n",
       "                                                                 stop_words=&#x27;english&#x27;)],\n",
       "                                         &#x27;vec__max_df&#x27;: [0.8, 0.9],\n",
       "                                         &#x27;vec__max_features&#x27;: [7000, 8000],\n",
       "                                         &#x27;vec__min_df&#x27;: [2, 3],\n",
       "                                         &#x27;vec__stop_words&#x27;: [None, &#x27;english&#x27;]}])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[(&#x27;vec&#x27;, None),\n",
       "                                             (&#x27;nb&#x27;, MultinomialNB())]),\n",
       "                   n_jobs=5,\n",
       "                   param_distributions=[{&#x27;nb__alpha&#x27;: [0.01, 0.5, 1.0, 5.0],\n",
       "                                         &#x27;vec&#x27;: [CountVectorizer(max_df=0.8,\n",
       "                                                                 max_features=7000,\n",
       "                                                                 min_df=3,\n",
       "                                                                 stop_words=&#x27;english&#x27;)],\n",
       "                                         &#x27;vec__max_df&#x27;: [0.8, 0.9],\n",
       "                                         &#x27;vec__max_features&#x27;: [7000, 8000],\n",
       "                                         &#x27;vec__min_df&#x27;: [2, 3],\n",
       "                                         &#x27;vec__stop_words&#x27;: [None, &#x27;english&#x27;]},\n",
       "                                        {&#x27;nb__alpha&#x27;: [0.01, 0.5, 1.0, 5.0],\n",
       "                                         &#x27;vec&#x27;: [TfidfVectorizer(max_df=0.8,\n",
       "                                                                 max_features=7000,\n",
       "                                                                 min_df=3,\n",
       "                                                                 stop_words=&#x27;english&#x27;)],\n",
       "                                         &#x27;vec__max_df&#x27;: [0.8, 0.9],\n",
       "                                         &#x27;vec__max_features&#x27;: [7000, 8000],\n",
       "                                         &#x27;vec__min_df&#x27;: [2, 3],\n",
       "                                         &#x27;vec__stop_words&#x27;: [None, &#x27;english&#x27;]}])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vec&#x27;, None), (&#x27;nb&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">None</label><div class=\"sk-toggleable__content\"><pre>None</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('vec', None),\n",
       "                                             ('nb', MultinomialNB())]),\n",
       "                   n_jobs=5,\n",
       "                   param_distributions=[{'nb__alpha': [0.01, 0.5, 1.0, 5.0],\n",
       "                                         'vec': [CountVectorizer(max_df=0.8,\n",
       "                                                                 max_features=7000,\n",
       "                                                                 min_df=3,\n",
       "                                                                 stop_words='english')],\n",
       "                                         'vec__max_df': [0.8, 0.9],\n",
       "                                         'vec__max_features': [7000, 8000],\n",
       "                                         'vec__min_df': [2, 3],\n",
       "                                         'vec__stop_words': [None, 'english']},\n",
       "                                        {'nb__alpha': [0.01, 0.5, 1.0, 5.0],\n",
       "                                         'vec': [TfidfVectorizer(max_df=0.8,\n",
       "                                                                 max_features=7000,\n",
       "                                                                 min_df=3,\n",
       "                                                                 stop_words='english')],\n",
       "                                         'vec__max_df': [0.8, 0.9],\n",
       "                                         'vec__max_features': [7000, 8000],\n",
       "                                         'vec__min_df': [2, 3],\n",
       "                                         'vec__stop_words': [None, 'english']}])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Test RandomizedSearch for comparison in timing and outcome\n",
    "rs_nb = RandomizedSearchCV(pipe_nb, pgrid_nb, cv=5, n_iter=10, n_jobs=5)\n",
    "rs_nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e7a875a9-ad4a-453e-adcb-6f2d4477fcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_nb_r = rs_nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6ee989f6-8016-495a-8e2a-682894c31a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- \u001b[1mMultinomial Bayes w/ RandomizedSearch\u001b[0m -------\n",
      "------------------- Train: 0.8808 -------------------\n",
      "------------------- Test: 0.8637 --------------------\n",
      "Best Params: {'vec__stop_words': 'english', 'vec__min_df': 3, 'vec__max_features': 7000, 'vec__max_df': 0.8, 'vec': CountVectorizer(max_df=0.8, max_features=7000, min_df=3, stop_words='english'), 'nb__alpha': 5.0}\n"
     ]
    }
   ],
   "source": [
    "print(f'------- {b1}Multinomial Bayes w/ RandomizedSearch{b0} -------')\n",
    "print(f'------------------- Train: {round(rs_nb.score(X_train, y_train),4)} -------------------')\n",
    "print(f'------------------- Test: {round(rs_nb.score(X_test, y_test),4)} --------------------')\n",
    "print('Best Params:', rs_nb.best_params_)\n",
    "\n",
    "# Randomized search computed faster and test score is slightly better - we will utilize RS more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d78a0687-6807-4761-8d93-46ccd544f27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code below was run with every rerun of this notebook and metrics were observed, commenting out to save computational power\n",
    "\n",
    "#%%time \n",
    "#RandomizedSearch gives a slightly different testing score and parameters each run (when done without random_state), I want to see the average and SD over 30 runs to make sure random \n",
    "    # parameters chosen from single run are reprsentative\n",
    "#num_runs = 35  # Number of runs\n",
    "#results = []\n",
    "\n",
    "#for i in range(num_runs):\n",
    "    #rs_nb = RandomizedSearchCV(pipe_nb, pgrid_nb, cv=5, n_iter=10, n_jobs=10)\n",
    "    #rs_nb.fit(X_train, y_train)\n",
    "    #results.append(rs_nb.score(X_test, y_test))\n",
    "    \n",
    "#scr = sum(results) / len(results)\n",
    "#scr_sd = (sum((i - scr)**2 for i in results) / len(results))**0.5\n",
    "#lcl = scr - 1.96*scr_sd\n",
    "#ucl = scr + 1.96*scr_sd\n",
    "\n",
    "#print(f'MEAN: {round(scr,4)}')\n",
    "#print(f'SD: {round(scr_sd,4)}')\n",
    "#print(f'95% CI: ({round(lcl,4)}, {round(ucl,4)})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "47a76170-a534-45bf-a5ba-9239cc2a7bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomSearch is not an exhaustive search within the predefined parameters grid, it randomly samples combinations,\n",
    "    # providing a more efficient exploration of the hyperparameter space. Each run of RandomSearch will give a different\n",
    "    # combination and therefore a slightly different training and testing accuracy score, sometimes even a better score than\n",
    "    # when using GridSearch. We will choose whichever had the higher score between the two.\n",
    "    \n",
    "final_nb_score = max(gs_nb.score(X_test, y_test), rs_nb.score(X_test, y_test))\n",
    "if (gs_nb.score(X_test, y_test)) > (rs_nb.score(X_test, y_test)):\n",
    "    final_nb_preds = preds_nb\n",
    "else:\n",
    "    final_nb_preds = preds_nb_r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9961e08-ab60-4a0e-a53d-5619e80b0e3e",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "#### Model 3: Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "49bbcdd0-bd17-42b7-9334-2f912ca1bbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_svc = Pipeline([\n",
    "    ('vec', None),\n",
    "    ('svc', SVC())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d3b4706d-457b-4c03-a1cc-094d385f233a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pgrid_svc =[\n",
    "    {\n",
    "     'vec': [CountVectorizer()],\n",
    "     'vec__stop_words': [None], #tested english stopwords as well\n",
    "     'vec__max_features': [7000], #also tested 8000 \n",
    "     'vec__min_df': [3, 5],\n",
    "     'vec__max_df': [0.80], #tested 0.90 as well\n",
    "     'svc__C': np.linspace(0.0001, 2, 10),\n",
    "     #'svc__kernel': ['rbf','poly'],\n",
    "     'svc__degree' : [2]\n",
    "    },\n",
    "    {\n",
    "     'vec': [TfidfVectorizer()],\n",
    "     'vec__stop_words': [None],\n",
    "     'vec__max_features': [7000], \n",
    "     'vec__min_df': [3, 5],\n",
    "     'vec__max_df': [0.80],\n",
    "     'svc__C': np.linspace(0.0001, 2, 10),\n",
    "     #'svc__kernel': ['rbf','poly'],\n",
    "     'svc__degree' : [2]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f932e6aa-040f-4e7e-96e9-7aba8268a14e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:2\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1387\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    814\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    815\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    818\u001b[0m         )\n\u001b[0;32m    819\u001b[0m     )\n\u001b[1;32m--> 821\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    822\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    823\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    836\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:1061\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1058\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1060\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1061\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1062\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1063\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:938\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    936\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    937\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 938\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    939\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    940\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    540\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 542\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\concurrent\\futures\\_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m--> 453\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "gs_svc = GridSearchCV(pipe_svc, pgrid_svc, n_jobs=25)\n",
    "gs_svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bc8a15-00e4-4f2d-bb5a-e806cec29879",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This GridSearchCV instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Make predictions for Accuracy Report\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m preds_svc \u001b[38;5;241m=\u001b[39m \u001b[43mgs_svc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:498\u001b[0m, in \u001b[0;36mBaseSearchCV.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    479\u001b[0m \u001b[38;5;129m@available_if\u001b[39m(_estimator_has(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m    480\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    481\u001b[0m     \u001b[38;5;124;03m\"\"\"Call predict on the estimator with the best found parameters.\u001b[39;00m\n\u001b[0;32m    482\u001b[0m \n\u001b[0;32m    483\u001b[0m \u001b[38;5;124;03m    Only available if ``refit=True`` and the underlying estimator supports\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    496\u001b[0m \u001b[38;5;124;03m        the best found parameters.\u001b[39;00m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 498\u001b[0m     \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_estimator_\u001b[38;5;241m.\u001b[39mpredict(X)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1390\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1385\u001b[0m     fitted \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   1386\u001b[0m         v \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(estimator) \u001b[38;5;28;01mif\u001b[39;00m v\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m v\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1387\u001b[0m     ]\n\u001b[0;32m   1389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fitted:\n\u001b[1;32m-> 1390\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This GridSearchCV instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "# Make predictions for Accuracy Report\n",
    "preds_svc = gs_svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac7ad8d-821e-4626-ada9-e47d69315c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'----------------- {b1}SVM w/ GridSearch{b0} ----------------')\n",
    "print(f'------------------ Train: {round(gs_svc.score(X_train, y_train),4)} -------------------')\n",
    "print(f'------------------- Test: {round(gs_svc.score(X_test, y_test),4)} -------------------')\n",
    "print('Best Params:', gs_svc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9983932b-6a8a-4e52-9827-99ed4e74f45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Test RandomizedSearch for comparison in timing and outcome\n",
    "rs_svc = RandomizedSearchCV(pipe_svc, pgrid_svc, cv=5, n_iter=10, n_jobs=15)\n",
    "rs_svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e866dcd-fa8e-4fe5-825b-4f8b9ef7b2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for Accuracy Report\n",
    "preds_svc_r = rs_svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc2a2d5-fc7a-4c39-a762-05002744b467",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'-------------- {b1}SVM w/ RandomizedSearch{b0} --------------')\n",
    "print(f'------------------- Train: {round(rs_svc.score(X_train, y_train),4)} -------------------')\n",
    "print(f'------------------- Test: {round(rs_svc.score(X_test, y_test),4)} --------------------')\n",
    "print('Best Params:', rs_svc.best_params_)\n",
    "\n",
    "# Randomized search computed faster and test score is slightly better - we will utilize RS more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9233ab0d-71aa-4f03-ae5a-048c2419e217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code below was run with every rerun of this notebook and metrics were observed, commenting out to save computational power\n",
    "\n",
    "#%%time \n",
    "#RandomizedSearch gives a slightly different testing score and parameters each run (when done without random_state), I want to see the average and SD over 30 runs to make sure random \n",
    "    # parameters chosen from single run are reprsentative\n",
    "#num_runs = 35  # Number of runs\n",
    "#results = []\n",
    "\n",
    "#for i in range(num_runs):\n",
    "    #rs_svc = RandomizedSearchCV(pipe_svc, pgrid_svc, cv=5, n_iter=10, n_jobs=15)\n",
    "    #rs_svc.fit(X_train, y_train)\n",
    "    #results.append(rs_svc.score(X_test, y_test))\n",
    "    \n",
    "#scr = sum(results) / len(results)\n",
    "#scr_sd = (sum((i - scr)**2 for i in results) / len(results))**0.5\n",
    "#lcl = scr - 1.96*scr_sd\n",
    "#ucl = scr + 1.96*scr_sd\n",
    "\n",
    "#print(f'MEAN: {round(scr,4)}')\n",
    "#print(f'SD: {round(scr_sd,4)}')\n",
    "#print(f'95% CI: ({round(lcl,4)}, {round(ucl,4)})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780d71b7-d82e-4a43-bd20-3f52ece59719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomSearch is not an exhaustive search within the predefined parameters grid, it randomly samples combinations,\n",
    "    # providing a more efficient exploration of the hyperparameter space. Each run of RandomSearch will give a different\n",
    "    # combination and therefore a slightly different training and testing accuracy score, sometimes even a better score than\n",
    "    # when using GridSearch. We will choose whichever had the higher score between the two.\n",
    "    \n",
    "final_svc_score = max(gs_svc.score(X_test, y_test), rs_svc.score(X_test, y_test))\n",
    "if (gs_svc.score(X_test, y_test)) > (rs_svc.score(X_test, y_test)):\n",
    "    final_svc_preds = preds_svc\n",
    "else:\n",
    "    final_svc_preds = preds_svc_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a45bdc-7c17-466c-903a-d2a4ee3f5e87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, final_log_preds, display_labels = ['Ski', 'Snowb'], cmap = 'Blues', ax=ax[0]);\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, final_nb_preds, display_labels = ['Ski', 'Snowb'], cmap = 'Greens', ax=ax[1]);\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, final_svc_preds, display_labels = ['Ski', 'Snowb'], cmap = 'Purples', ax=ax[2]);\n",
    "\n",
    "plt.tight_layout()\n",
    "ax[0].set_title('Logistic Regression')\n",
    "ax[1].set_title('Multinomial Naive Bayes')\n",
    "ax[2].set_title('Support Vector Machine');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df475f4e-26b0-4b2f-b036-2fa316a5881a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'\\n---------------------- {b1}Logistic{b0} ---------------------- \\n {classification_report(y_test, final_log_preds, digits=4)} \\n')\n",
    "print(f'------------------------- {b1}NB{b0} ------------------------- \\n  {classification_report(y_test, final_nb_preds, digits=4)} \\n')\n",
    "print(f'------------------------- {b1}SVM{b0} ------------------------- \\n  {classification_report(y_test, final_svc_preds, digits=4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1617efe-b443-47ad-8b2c-2cc5beb77494",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### <span style = 'color: blue'> <u>**Outcomes and Comparison**</u>: </span>\n",
    "\n",
    "- <span style = 'color: blue'>The **Logistic Regression** model best parameters included:</span>\n",
    "    - <span style = 'color: blue'>TfidfVectorizer</span>\n",
    "        - <span style = 'color: blue'>max_df=0.85</span>\n",
    "        - <span style = 'color: blue'>max_features=8000</span>\n",
    "        - <span style = 'color: blue'>min_df=2</span>\n",
    "        - <span style = 'color: blue'>stop_words=None </span>\n",
    "    - <span style = 'color: blue'>'logr__C': 5.5778</span>\n",
    "    - <span style = 'color: blue'>'logr__penalty': 'l2'</span>\n",
    "    <br></br>\n",
    "\n",
    "- <span style = 'color: blue'>The **Multinomial Bayes** model best parameters included:</span>\n",
    "     - <span style = 'color: blue'>TfidfVectorizer\n",
    "        - max_df=0.8\n",
    "        - max_features=7000\n",
    "        - min_df=3\n",
    "        - stop_words='english'\n",
    "    - <span style = 'color: blue'>'nb__alpha': 5.0\n",
    "    <br></br>\n",
    "        \n",
    "- <span style = 'color: blue'>The **Support Vector Machine** model best parameters included:</span>\n",
    "    - <span style = 'color: blue'>TfidfVectorizer</span>\n",
    "        - <span style = 'color: blue'>max_df=0.8</span>\n",
    "        - <span style = 'color: blue'>max_features=7000</span>\n",
    "        - <span style = 'color: blue'>min_df=3\n",
    "        - <span style = 'color: blue'>stop_words': None</span>\n",
    "    - <span style = 'color: blue'>'svc__C': 1.7778 </span>\n",
    "    - <span style = 'color: blue'>'svc__degree': 2 </span>      <br></br>\n",
    "- <span style = 'color: blue'>The **Logistic Regression (LR)** and **Support Vector Machine (SVM)** had similar performances, and both performed better than Multinomial Naive Bayes (MNB).</span>\n",
    "    - <span style = 'color: blue'>The LR had ...\n",
    "        - A higher testing **accuracy** score than both SVM and MNB (LR: 88.4% vs. SVM: 88.3% and MNB: 85.7%) \n",
    "        - A **precision** of 91.3% (compared to SVM: 92.0% and MNB: 83.8%)\n",
    "        - A **sensitivity** of 85.2% (compared to SVM: 84.4% and MNB: 89.0%)\n",
    "        - A **specificity** of 91.6% (compared to SVM: 92.3% and MNB: 82.2%)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72efebd0-f694-423a-8398-fac53df0d74c",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "### Ensembling\n",
    "##### Here we will test if Ensembling Models 1-3 makes a better model, by how much, and any other considerations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc57958d-daf7-4bc2-86d1-b4cecf675879",
   "metadata": {},
   "outputs": [],
   "source": [
    "vc = VotingClassifier([\n",
    "    ('logr_e', rs_log), \n",
    "    ('nb_e', rs_nb),\n",
    "    ('svc_e', gs_svc)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cf6d4c-e8fc-469b-9b72-82202ac5e286",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "vc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ac3dcd-4969-45f1-ba04-db2823b7e898",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'----------------- {b1}Ensembling Scores{b0} -----------------')\n",
    "print(f'------------------- Train: {round(vc.score(X_train, y_train),4)} -------------------')\n",
    "print(f'-------------------- Test: {round(vc.score(X_test, y_test),4)} -------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a66ce2d-0b3a-4678-8fc4-4a25fa442e55",
   "metadata": {},
   "source": [
    "##### <span style = 'color:blue'> Ensembling all three models we built did not improve testing accuracy, therefore we will not proceed with this approach as the gain is insufficient. We instead turn our attention to attempting to reduce any overfitting.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e43d7e7-e15d-48d6-b8f8-a6f288b933a7",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "### Reducing Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b964add5-23c5-4148-99ea-70fae255f1b3",
   "metadata": {},
   "source": [
    "\n",
    "#### Model 4: Random Forest and ExtraTrees\n",
    "##### This model will be attempting to address overfitting. All three models that have been fit have higher training scores than testing scores by ~4-10%:\n",
    "- Logistic Regression\n",
    "    - Train = 0.9728\n",
    "    - Test: 0.8836   \n",
    "- Multinomial Naive Bayes\n",
    "    - Train = 0.9025\n",
    "    - Test = 0.8595\n",
    "- Support Vector Machine\n",
    "    - Train = 0.9875\n",
    "    - Test = 0.8772\n",
    "    \n",
    "##### We will test Random Forest Classifier and Extra Trees to see if either ameliorates this impact and improves our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8bb722-4d13-4e00-9b93-33a9afce5153",
   "metadata": {},
   "source": [
    "##### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6febfd9-541f-46db-ace0-dfb7d8af2334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANDOM FOREST\n",
    "pipe_rf = Pipeline([\n",
    "    ('vec', None),\n",
    "    ('rf', RandomForestClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46575c61-d96a-46b4-bbc0-9d88004e7017",
   "metadata": {},
   "outputs": [],
   "source": [
    "pgrid_rf =[\n",
    "    {\n",
    "    'vec': [CountVectorizer()],\n",
    "    'vec__stop_words': [None], #tested english as well\n",
    "    'vec__max_features': [7000], #tested 8000 as well\n",
    "    'vec__min_df': [3, 5],\n",
    "    'vec__max_df': [0.80],\n",
    "    'rf__n_estimators': [300, 350],\n",
    "    'rf__max_depth': [50]\n",
    "    },\n",
    "    {\n",
    "    'vec': [TfidfVectorizer()],\n",
    "    'vec__stop_words': [None],\n",
    "    'vec__max_features': [7000], \n",
    "    'vec__min_df': [3, 5],\n",
    "    'vec__max_df': [0.80],\n",
    "    'rf__n_estimators': [300, 350],\n",
    "    'rf__max_depth': [50]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b746a6-d011-40bf-bf81-0a226d043c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "gs_rf = GridSearchCV(pipe_rf, pgrid_rf, cv=5, n_jobs=25)\n",
    "gs_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d16237c-1805-49ad-9f6d-4c0d48f0331a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for Accuracy Report\n",
    "preds_rf = gs_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e93412-4893-4b7e-ae7a-449692fe7da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'------------- {b1}Random Forest w/ GridSearch{b0} ------------')\n",
    "print(f'------------------- Train: {round(gs_rf.score(X_train, y_train),4)} --------------------')\n",
    "print(f'------------------- Test: {round(gs_rf.score(X_test, y_test),4)} ---------------------')\n",
    "print('Best Params:', gs_rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad24492-d887-4517-8f64-9204cfdec4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "rs_rf = RandomizedSearchCV(pipe_rf, pgrid_rf, cv=5, n_iter = 10, n_jobs=25)\n",
    "rs_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8f0861-f9b1-4c5c-a64e-4fa10165a65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for Accuracy Report\n",
    "preds_rf_r = rs_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd5b522-8a3e-4330-8ec6-727cbda6cd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'--------- {b1}Random Forest w/ RandomizedSearch{b0} ---------')\n",
    "print(f'-------------------- Train: {round(rs_rf.score(X_train, y_train),4)} ------------------')\n",
    "print(f'-------------------- Test: {round(rs_rf.score(X_test, y_test),4)} -------------------')\n",
    "print('Best Params:', rs_rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bea0e2e-3a69-451c-b9d5-b88d9546aa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomSearch is not an exhaustive search within the predefined parameters grid, it randomly samples combinations,\n",
    "    # providing a more efficient exploration of the hyperparameter space. Each run of RandomSearch will give a different\n",
    "    # combination and therefore a slightly different training and testing accuracy score, sometimes even a better score than\n",
    "    # when using GridSearch. We will choose whichever had the higher score between the two.\n",
    "    \n",
    "final_rf_score = max(gs_rf.score(X_test, y_test), rs_rf.score(X_test, y_test))\n",
    "if (gs_rf.score(X_test, y_test)) > (rs_rf.score(X_test, y_test)):\n",
    "    final_rf_preds = preds_rf\n",
    "    final_rf = gs_rf\n",
    "else:\n",
    "    final_rf_preds = preds_rf_r\n",
    "    final_rf = rs_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca4e83c-aebc-42f0-9c19-8e8382404365",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_rf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe5c269-fe58-45bb-828a-e4bc0e28f77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_rf.best_estimator_.named_steps['rf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43c6d79-f666-4851-94ce-12d2739bb689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: https://github.com/scikit-learn/scikit-learn/issues/21349, ChatGPT\n",
    "best_estimator = final_rf.best_estimator_\n",
    "random_forest = best_estimator.named_steps['rf']\n",
    "feature_importances = random_forest.feature_importances_\n",
    "\n",
    "vec = best_estimator.named_steps['vec']\n",
    "if isinstance(vec, CountVectorizer):\n",
    "    feature_names = vec.get_feature_names_out()\n",
    "elif isinstance(vec, TfidfVectorizer):\n",
    "    feature_names = vec.transformer_.get_feature_names_out()\n",
    "\n",
    "print(feature_names)\n",
    "print(feature_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a98905-1810-4219-bac7-1c96157450e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make df\n",
    "df = pd.DataFrame({'feature_names':feature_names,\n",
    "                   'feature_importance': feature_importances})\n",
    "\n",
    "#Sort by creasing feature importance\n",
    "df.sort_values(by=['feature_importance'], ascending=False,inplace=True)\n",
    "df2 = df.reset_index().drop(columns = ['index']).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f488c9-c93f-4031-a75e-7c26f8291bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort the DataFrame by descending\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.barplot(x=df2['feature_importance'], y=df2['feature_names'])\n",
    "plt.title('Random Forest Top 30 Feature Importances')\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Feature Names');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1941d155-ac65-4e3c-9ad0-9e731360e60d",
   "metadata": {},
   "source": [
    "##### Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c23609-53a9-49c4-aabd-41d0345eda93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRA TREES\n",
    "pipe_et = Pipeline([\n",
    "    ('vec', None),\n",
    "    ('et', ExtraTreesClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bfc44d-8a52-44d6-bddd-9b460d7c38fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pgrid_et =[\n",
    "    {\n",
    "    'vec': [CountVectorizer()],\n",
    "    'vec__stop_words': ['english'], #tested None as well\n",
    "    'vec__max_features': [7000], #tested 8000 as well\n",
    "    'vec__min_df': [3, 5],\n",
    "    'vec__max_df': [0.80],\n",
    "    'et__n_estimators': [300, 350],\n",
    "    'et__max_depth': [50]\n",
    "    },\n",
    "    {\n",
    "    'vec': [TfidfVectorizer()],\n",
    "    'vec__stop_words': ['english'],\n",
    "    'vec__max_features': [7000], \n",
    "    'vec__min_df': [3, 5],\n",
    "    'vec__max_df': [0.80],\n",
    "    'et__n_estimators': [300, 350],\n",
    "    'et__max_depth': [50]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb49481a-f727-48ba-b9a3-ec2573e11a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "gs_et = GridSearchCV(pipe_et, pgrid_et, cv=5, n_jobs=25)\n",
    "gs_et.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fed2019-2a55-4efb-a257-711746654c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for Accuracy Report\n",
    "preds_et = gs_et.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50c50fb-afa5-4be9-8b51-d88c5c3bea28",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'------------- {b1}Extra Trees w/ GridSearch{b0} -------------')\n",
    "print(f'------------------- Train: {round(gs_et.score(X_train, y_train),4)} -------------------')\n",
    "print(f'------------------- Test: {round(gs_et.score(X_test, y_test),4)} --------------------')\n",
    "print('Best Params:', gs_et.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43994332-958f-4a59-b056-9ce864fea6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_et.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881601f9-532d-43e3-8f8d-93226849af5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "rs_et = RandomizedSearchCV(pipe_et, pgrid_et, cv=5, n_iter = 10, n_jobs=25)\n",
    "rs_et.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bf5cf8-0d45-4385-aa40-c2fca92dd7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for Accuracy Report\n",
    "preds_et_r = rs_et.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d746d55-e6df-47cc-9d8e-6168368c5dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'---------- {b1}Extra Trees w/ RandomizedSearch{b0} ----------')\n",
    "print(f'------------------- Train: {round(rs_et.score(X_train, y_train),4)} -------------------')\n",
    "print(f'------------------- Test: {round(rs_et.score(X_test, y_test),4)} --------------------')\n",
    "print('Best Params:', rs_et.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49984656-12cc-47c1-9b47-8305bbf5b874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomSearch is not an exhaustive search within the predefined parameters grid, it randomly samples combinations,\n",
    "    # providing a more efficient exploration of the hyperparameter space. Each run of RandomSearch will give a different\n",
    "    # combination and therefore a slightly different training and testing accuracy score, sometimes even a better score than\n",
    "    # when using GridSearch. We will choose whichever had the higher score between the two.\n",
    "    \n",
    "final_et_score = max(gs_et.score(X_test, y_test), rs_et.score(X_test, y_test))\n",
    "if (gs_et.score(X_test, y_test)) > (rs_et.score(X_test, y_test)):\n",
    "    final_et_preds = preds_et\n",
    "    final_et = gs_et\n",
    "else:\n",
    "    final_et_preds = preds_et_r\n",
    "    final_et = rs_et"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27a04c6-f8c2-45cf-a01b-e74a6e0c51a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_et.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b1061e-b86e-4199-ab7d-dd25b960db80",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_et.best_estimator_.named_steps['et']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81acd1d9-6a85-4b1e-aa63-c91250c4ac11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: https://github.com/scikit-learn/scikit-learn/issues/21349, ChatGPT\n",
    "best_estimator = final_et.best_estimator_\n",
    "random_forest = best_estimator.named_steps['et']\n",
    "feature_importances = random_forest.feature_importances_\n",
    "\n",
    "vec = best_estimator.named_steps['vec']\n",
    "if isinstance(vec, CountVectorizer):\n",
    "    feature_names = vec.get_feature_names_out()\n",
    "elif isinstance(vec, TfidfVectorizer):\n",
    "    feature_names = vec.transformer_.get_feature_names_out()\n",
    "\n",
    "print(feature_names)\n",
    "print(feature_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e75fa14-0262-4bd4-aee0-aa033e134cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make df\n",
    "df = pd.DataFrame({'feature_names':feature_names,\n",
    "                   'feature_importance': feature_importances})\n",
    "\n",
    "#Sort by creasing feature importance\n",
    "df.sort_values(by=['feature_importance'], ascending=False,inplace=True)\n",
    "df2 = df.reset_index().drop(columns = ['index']).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525cae8d-51b9-4840-bce6-809169ba24ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort the DataFrame by descending\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.barplot(x=df2['feature_importance'], y=df2['feature_names'])\n",
    "plt.title('Extra Trees Top 30 Feature Importances')\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Feature Names');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f239b59-21da-451e-a151-ca550d2214f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'---------------- {b1}Random Forest Final{b0} ----------------')\n",
    "print(f'------------------- Train: {round(final_rf.score(X_train, y_train),4)} -------------------')\n",
    "print(f'------------------- Test: {round(final_rf.score(X_test, y_test),4)} --------------------\\n')\n",
    "\n",
    "print(f'----------------- {b1}Extra Trees Final{b0} -----------------')\n",
    "print(f'------------------- Train: {round(final_et.score(X_train, y_train),4)} -------------------')\n",
    "print(f'------------------- Test: {round(final_et.score(X_test, y_test),4)} --------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315c2752-3dcd-44a0-a50a-40d35427f82c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed761c15-886e-419c-81f7-c7f120568355",
   "metadata": {},
   "source": [
    "### III. Model Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc864b5-42f9-4a52-b223-f7589062b8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking the best model between the Gridsearches and Randomizedsearches\n",
    "summ = [final_log_score,\n",
    "        final_nb_score, \n",
    "        final_svc_score), \n",
    "        vc.score(X_test, y_test),\n",
    "        final_rf_score, \n",
    "        final_et_score]\n",
    "mod = ['Logistic Regression', 'Multinomial Bayes', 'Support Vector Machine', 'Ensemble', 'Random Forest', 'Extra Trees']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3671ec93-4c71-443e-8dd2-c3522a1197df",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall = pd.DataFrame({'Model': mod, 'Test_Score': summ})\n",
    "overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e53af8-ae49-46c0-85e5-f3521e533131",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "overall.sort_values(by = 'Test_Score', ascending=False, inplace=True)\n",
    "sns.barplot(y=overall['Model'], x=overall['Test_Score'], order=overall['Model'])\n",
    "plt.title('Model Performance')\n",
    "plt.xlabel('Testing Score')\n",
    "plt.ylabel(None)\n",
    "\n",
    "\n",
    "# Add bar values\n",
    "# source: https://stackoverflow.com/questions/30228069/how-to-display-the-value-on-horizontal-bars, ChatGPT\n",
    "for i, score in enumerate(overall['Test_Score']):\n",
    "    plt.text(score, i, f\"{score:.4f}\", va='center', ha='left')\n",
    "plt.xlim(0, max(overall['Test_Score']) + .09);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dc8500-9815-4503-937d-399b623cef05",
   "metadata": {},
   "source": [
    "### IV. Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd03803-2eb6-49c6-bd4a-5b68b19fa9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pipe_logr = Pipeline([\n",
    "                 ('tvec', TfidfVectorizer(max_df=0.85, max_features=8000, min_df=2)),\n",
    "                 ('logr', LogisticRegression(C=5.577778, penalty='l2'))\n",
    "])\n",
    "pipe_logr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19825c6b-e67b-4544-a634-1d51033254d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'~~~~~~~~~~~~ {b1}FINAL MODEL: LOGISTIC REGRESSION{b0} ~~~~~~~~~~~')\n",
    "print(f'~~~~~~~~~~~~~~~~~~~~~ Train: {round(pipe_logr.score(X_train, y_train),4)} ~~~~~~~~~~~~~~~~~~~~~')\n",
    "print(f'~~~~~~~~~~~~~~~~~~~~~ Test: {round(pipe_logr.score(X_test, y_test),4)} ~~~~~~~~~~~~~~~~~~~~~~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4649bb-7fcf-49f0-9307-abd8f485aaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pipe_svc = Pipeline([\n",
    "                 ('tvec', TfidfVectorizer(max_df=0.8, max_features=7000, min_df=3)),\n",
    "                 ('svc', SVC(C=1.77779, degree=2))\n",
    "])\n",
    "pipe_svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f964a2-6ebc-45dc-a548-014171085d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'~~~~~~~~~~~~~~ {b1}RUNNER UP: SVM MODEL{b0} ~~~~~~~~~~~~~~')\n",
    "print(f'~~~~~~~~~~~~~~~~~~ Train: {round(pipe_svc.score(X_train, y_train),4)} ~~~~~~~~~~~~~~~~~')\n",
    "print(f'~~~~~~~~~~~~~~~~~~ Test: {round(pipe_svc.score(X_test, y_test),4)} ~~~~~~~~~~~~~~~~~~')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511da9a7-2935-49c3-8d36-8ec7e089b38c",
   "metadata": {},
   "source": [
    "##### <span style = 'color:blue'>Both Logistic Regression and SVM performed similarly in terms of their testing accuracy score (88.4% vs. 88.3%). Logistic Regression had a slightly lower precision (91.3% vs. 92.0%), a slightly higher sensitivity (85.2% vs. 84.4%), and a slightly lower specificity (91.6% vs. 92.3%). This means that...\n",
    "- <span style = 'color:blue'>Of all the posts that our Logistic Regression model predicted would be from the Snowboarding subreddit, 91.3% were classified correctly.\n",
    "- <span style = 'color:blue'>Of all the posts that were from the Snowboarding subreddit, the Logistic Regression model predicted this outcome correctly 85.2% of the time.\n",
    "- <span style = 'color:blue'>OF all the posts that were from the Skiing subreddit, the Logistic Regression model predicted this outcome correctly 91.6% of the time.\n",
    "- <span style = 'color:blue'>The Logistic Regression is slightly more likely to commit Type I errors than the SVM, that is, it is more likely to mis-classify Skiers as Snowboarders (e.g., incorrectly predict the positive class).\n",
    "- <span style = 'color:blue'>The Logistic Regression is slightly less likely to commit Type II errors than the SVM, that is, it is less likely to mis-classify Snowboarders as Skiers (e.g., incorrectly predict the negative class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad53e41b-ba38-4ec0-9c92-24fed41b95c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f3047c-1779-4b9c-8e9b-9d327eb2fa24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d986f4f2-0d55-49ae-bcfb-b34eba0ceca6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fceab2c8-b045-4069-84e4-f444379e483e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipe_logr = Pipeline([\n",
    "                 #('tvec', TfidfVectorizer(max_df=0.85, max_features=7000, min_df=2, stop_words='english')),\n",
    "                 #('logr', LogisticRegression(penalty='l2', C=2.261))\n",
    "#])\n",
    "#pipe_logr.fit(X_train, y_train)\n",
    "\n",
    "#print('Train:', round(pipe_logr.score(X_train, y_train),4))\n",
    "#print('Test:', round(pipe_logr.score(X_test, y_test),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5605017b-a8c0-4052-a4be-4013adba68a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#pipe_logr2 = Pipeline([\n",
    "                 #('tvec', TfidfVectorizer(max_df=0.85, max_features=7000, min_df=2)),\n",
    "                 #('logr', LogisticRegression(penalty='l2', C=4.472))\n",
    "#])\n",
    "#pipe_logr2.fit(X_train, y_train)\n",
    "\n",
    "#print('Train:', round(pipe_logr2.score(X_train, y_train),4))\n",
    "#print('Test:', round(pipe_logr2.score(X_test, y_test),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0737f2a9-be24-4dc1-87b6-2440385d76cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM: Best Params: {'svc__C': 1.5, 'svc__degree': 2, 'vec': TfidfVectorizer(max_df=0.8, max_features=7000, min_df=3), 'vec__max_df': 0.8, 'vec__max_features': 7000, 'vec__min_df': 3, 'vec__stop_words': None} -->0.8829\n",
    "#Best Params: {'svc__C': 1.7777888888888889, 'svc__degree': 2, 'vec': TfidfVectorizer(max_df=0.8, max_features=7000, min_df=3), 'vec__max_df': 0.8, 'vec__max_features': 7000, 'vec__min_df': 3, 'vec__stop_words': None}--0.877"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2b3cae-340b-4a43-806e-089df992234c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770b5959-6dfc-4928-9c05-7582efb17b58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7544d0-ee51-4e02-ad85-016e1d16e2b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f623fa21-fb9c-4feb-bc69-d4d3f24e0be1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bd34c2-1a68-436d-a368-a9d003860bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOGISTIC RANDOMIZED: Best Params: {'vec__stop_words': None, 'vec__min_df': 2, 'vec__max_features': 7000, 'vec__max_df': 0.95, 'vec': TfidfVectorizer(max_df=0.95, max_features=8000, min_df=2), 'logr__penalty': 'l2', 'logr__C': 4.472222222222221}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a4c393-f545-4b1f-930e-a8d85c97b33e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46c9245-95c9-41e6-bc38-3f9cf4fc19e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172cb42f-d8cf-422b-b217-2b69562fb05d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a3f74c-c31e-42c0-b563-4e389562ee1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "#pgrid_logr =[\n",
    "    #{\n",
    "    #'vec': [CountVectorizer()],\n",
    "    #'vec__stop_words': [None, 'english'],\n",
    "    #'vec__max_features': [7000, 8000], \n",
    "    #'vec__min_df': [2, 3],\n",
    "    #'vec__max_df': [0.85], #tested 0.8, 0.95 as well\n",
    "    #'vec__preprocessor': [None, lemmatize_txt, stem_txt],\n",
    "    #'logr__C': np.linspace(.05,10.0,10),\n",
    "    #'logr__penalty': ['l2'] #tested l1, l2 was more optimal\n",
    "    #},\n",
    "    #{\n",
    "    #'vec': [TfidfVectorizer()],\n",
    "    #'vec__stop_words': [None, 'english'],\n",
    "    #'vec__max_features': [7000, 8000], \n",
    "    #'vec__min_df': [2, 3],\n",
    "    #'vec__max_df': [0.85],\n",
    "    #'vec__preprocessor': [None, lemmatize_txt, stem_txt],\n",
    "    #'logr__C': np.linspace(.05,10.0,10),\n",
    "    #'logr__penalty': ['l2']\n",
    "    #}\n",
    "#]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2ec6df-167d-4fae-874c-28804033a47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "\n",
    "# Test RandomizedSearch for comparison in timing and outcome\n",
    "#rs_log = RandomizedSearchCV(pipe_log, pgrid_logr, cv=5, n_iter=10, n_jobs=10)\n",
    "#rs_log.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38688685-f0b3-4663-9237-d994c28c7a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f'--------- {b1}Logistic Regression w/ GridSearch{b0} ---------') # source: https://stackoverflow.com/questions/8924173/how-can-i-print-bold-text-in-python\n",
    "#print(f'------------------- Train: {round(rs_log.score(X_train, y_train),4)} -------------------')\n",
    "#print(f'------------------- Test: {round(rs_log.score(X_test, y_test),4)} --------------------')\n",
    "#print('Best Params:', rs_log.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7c4455-3334-4e7a-a3d8-7358e1db0bde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e93ba2-0a4e-48f2-8e7b-2cd72305ac31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
