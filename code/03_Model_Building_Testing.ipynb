{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce93ea2a-d6a4-42e7-8e87-2d5be052073e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406b8a8b-9141-4e23-8a4a-6497bdaed0fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c48f2112-dd49-4d66-bd5d-91f13511d611",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c71b8cac-022c-42d3-b0e0-9ce0743fb63a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_utc</th>\n",
       "      <th>author</th>\n",
       "      <th>score</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>text</th>\n",
       "      <th>lem_text</th>\n",
       "      <th>stem_text</th>\n",
       "      <th>post_length</th>\n",
       "      <th>post_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.686844e+09</td>\n",
       "      <td>bas1cred</td>\n",
       "      <td>26</td>\n",
       "      <td>0.91</td>\n",
       "      <td>19</td>\n",
       "      <td>snowboardingnoobs</td>\n",
       "      <td>my first board. ready for the upcoming season!!</td>\n",
       "      <td>my first board ready for the upcoming season</td>\n",
       "      <td>my first board readi for the upcom season</td>\n",
       "      <td>48</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.686786e+09</td>\n",
       "      <td>Pooffios</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>12</td>\n",
       "      <td>snowboardingnoobs</td>\n",
       "      <td>outer side foot pain hi all, i was hoping to g...</td>\n",
       "      <td>outer side foot pain hi all i wa hoping to get...</td>\n",
       "      <td>outer side foot pain hi all i wa hope to get s...</td>\n",
       "      <td>301</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.686781e+09</td>\n",
       "      <td>trips69420</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>15</td>\n",
       "      <td>snowboardingnoobs</td>\n",
       "      <td>first board? looking to probably grab this as ...</td>\n",
       "      <td>first board looking to probably grab this a my...</td>\n",
       "      <td>first board look to probabl grab thi as my fir...</td>\n",
       "      <td>274</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.686779e+09</td>\n",
       "      <td>twinbee</td>\n",
       "      <td>11</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0</td>\n",
       "      <td>snowboardingnoobs</td>\n",
       "      <td>i did a front-side 180 today! more than one in...</td>\n",
       "      <td>i did a front side 180 today more than one in ...</td>\n",
       "      <td>i did a front side 180 today more than one in ...</td>\n",
       "      <td>1565</td>\n",
       "      <td>289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.686767e+09</td>\n",
       "      <td>Madden_Stephen</td>\n",
       "      <td>2</td>\n",
       "      <td>0.67</td>\n",
       "      <td>24</td>\n",
       "      <td>snowboardingnoobs</td>\n",
       "      <td>step-on boot recommendation? i’ve done a decen...</td>\n",
       "      <td>step on boot recommendation i ve done a decent...</td>\n",
       "      <td>step on boot recommend i ve done a decent bit ...</td>\n",
       "      <td>686</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    created_utc          author  score  upvote_ratio  num_comments  \\\n",
       "0  1.686844e+09        bas1cred     26          0.91            19   \n",
       "1  1.686786e+09        Pooffios      3          1.00            12   \n",
       "2  1.686781e+09      trips69420      2          0.75            15   \n",
       "3  1.686779e+09         twinbee     11          0.87             0   \n",
       "4  1.686767e+09  Madden_Stephen      2          0.67            24   \n",
       "\n",
       "           subreddit                                               text  \\\n",
       "0  snowboardingnoobs   my first board. ready for the upcoming season!!    \n",
       "1  snowboardingnoobs  outer side foot pain hi all, i was hoping to g...   \n",
       "2  snowboardingnoobs  first board? looking to probably grab this as ...   \n",
       "3  snowboardingnoobs  i did a front-side 180 today! more than one in...   \n",
       "4  snowboardingnoobs  step-on boot recommendation? i’ve done a decen...   \n",
       "\n",
       "                                            lem_text  \\\n",
       "0       my first board ready for the upcoming season   \n",
       "1  outer side foot pain hi all i wa hoping to get...   \n",
       "2  first board looking to probably grab this a my...   \n",
       "3  i did a front side 180 today more than one in ...   \n",
       "4  step on boot recommendation i ve done a decent...   \n",
       "\n",
       "                                           stem_text  post_length  \\\n",
       "0          my first board readi for the upcom season           48   \n",
       "1  outer side foot pain hi all i wa hope to get s...          301   \n",
       "2  first board look to probabl grab thi as my fir...          274   \n",
       "3  i did a front side 180 today more than one in ...         1565   \n",
       "4  step on boot recommend i ve done a decent bit ...          686   \n",
       "\n",
       "   post_word_count  \n",
       "0                8  \n",
       "1               60  \n",
       "2               53  \n",
       "3              289  \n",
       "4              122  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowski = pd.read_csv('../data/Clean/snow_ski2.csv')\n",
    "snowski.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "298e0599-3b3e-4075-8eff-37d69092b5f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "skiing               0.51242\n",
       "snowboardingnoobs    0.48758\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowski.subreddit.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8c48eb3-b3d6-49e5-b388-9efea837d0eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_utc</th>\n",
       "      <th>author</th>\n",
       "      <th>score</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>text</th>\n",
       "      <th>lem_text</th>\n",
       "      <th>stem_text</th>\n",
       "      <th>post_length</th>\n",
       "      <th>post_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.686844e+09</td>\n",
       "      <td>bas1cred</td>\n",
       "      <td>26</td>\n",
       "      <td>0.91</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>my first board. ready for the upcoming season!!</td>\n",
       "      <td>my first board ready for the upcoming season</td>\n",
       "      <td>my first board readi for the upcom season</td>\n",
       "      <td>48</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.686786e+09</td>\n",
       "      <td>Pooffios</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>outer side foot pain hi all, i was hoping to g...</td>\n",
       "      <td>outer side foot pain hi all i wa hoping to get...</td>\n",
       "      <td>outer side foot pain hi all i wa hope to get s...</td>\n",
       "      <td>301</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.686781e+09</td>\n",
       "      <td>trips69420</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>first board? looking to probably grab this as ...</td>\n",
       "      <td>first board looking to probably grab this a my...</td>\n",
       "      <td>first board look to probabl grab thi as my fir...</td>\n",
       "      <td>274</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.686779e+09</td>\n",
       "      <td>twinbee</td>\n",
       "      <td>11</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>i did a front-side 180 today! more than one in...</td>\n",
       "      <td>i did a front side 180 today more than one in ...</td>\n",
       "      <td>i did a front side 180 today more than one in ...</td>\n",
       "      <td>1565</td>\n",
       "      <td>289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.686767e+09</td>\n",
       "      <td>Madden_Stephen</td>\n",
       "      <td>2</td>\n",
       "      <td>0.67</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>step-on boot recommendation? i’ve done a decen...</td>\n",
       "      <td>step on boot recommendation i ve done a decent...</td>\n",
       "      <td>step on boot recommend i ve done a decent bit ...</td>\n",
       "      <td>686</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    created_utc          author  score  upvote_ratio  num_comments  subreddit  \\\n",
       "0  1.686844e+09        bas1cred     26          0.91            19          1   \n",
       "1  1.686786e+09        Pooffios      3          1.00            12          1   \n",
       "2  1.686781e+09      trips69420      2          0.75            15          1   \n",
       "3  1.686779e+09         twinbee     11          0.87             0          1   \n",
       "4  1.686767e+09  Madden_Stephen      2          0.67            24          1   \n",
       "\n",
       "                                                text  \\\n",
       "0   my first board. ready for the upcoming season!!    \n",
       "1  outer side foot pain hi all, i was hoping to g...   \n",
       "2  first board? looking to probably grab this as ...   \n",
       "3  i did a front-side 180 today! more than one in...   \n",
       "4  step-on boot recommendation? i’ve done a decen...   \n",
       "\n",
       "                                            lem_text  \\\n",
       "0       my first board ready for the upcoming season   \n",
       "1  outer side foot pain hi all i wa hoping to get...   \n",
       "2  first board looking to probably grab this a my...   \n",
       "3  i did a front side 180 today more than one in ...   \n",
       "4  step on boot recommendation i ve done a decent...   \n",
       "\n",
       "                                           stem_text  post_length  \\\n",
       "0          my first board readi for the upcom season           48   \n",
       "1  outer side foot pain hi all i wa hope to get s...          301   \n",
       "2  first board look to probabl grab thi as my fir...          274   \n",
       "3  i did a front side 180 today more than one in ...         1565   \n",
       "4  step on boot recommend i ve done a decent bit ...          686   \n",
       "\n",
       "   post_word_count  \n",
       "0                8  \n",
       "1               60  \n",
       "2               53  \n",
       "3              289  \n",
       "4              122  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowski['subreddit'] = snowski['subreddit'].map({'snowboardingnoobs': 1, 'skiing': 0})\n",
    "snowski.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d8c3d80-13b8-4502-9eee-709e175b5598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for Lemmatizing\n",
    "def lemmatize_txt(text):\n",
    "    \n",
    "    tokenizer = RegexpTokenizer('\\w+')\n",
    "    split_txt = tokenizer.tokenize(text)\n",
    "\n",
    "    # Instantiate lemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "        \n",
    "    # Lemmatize and Rejoin\n",
    "    return ' '.join([lemmatizer.lemmatize(word) for word in split_txt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8c689b2-7de9-4fa1-bab9-f41c6a8e57d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for Stemming\n",
    "def stem_txt(text):\n",
    "    \n",
    "    tokenizer = RegexpTokenizer('\\w+')\n",
    "    split_txt = tokenizer.tokenize(text)\n",
    "\n",
    "    # Instantiate Stemmer\n",
    "    p_stemmer = PorterStemmer()\n",
    "\n",
    "    # Stem and Rejoin\n",
    "    return ' '.join([p_stemmer.stem(word) for word in split_txt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d431b26d-a73c-4635-820f-4d5da1097192",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = snowski['text']\n",
    "y = snowski['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0aa70b5-0d7c-4394-a412-eed5aadef0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 1527) # Jokic and Jamal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ec0ce7f-3c25-4547-819e-dbb366be8941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4227,)\n",
      "(1409,)\n",
      "(4227,)\n",
      "(1409,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc035312-694c-470d-8a4e-b92acca3687e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Models via Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96e7c5d0-c2d4-4db5-9809-ca7dd92c7245",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_log = Pipeline([\n",
    "                 ('vec', None),\n",
    "                 ('logr', LogisticRegression(solver = 'liblinear'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76943560-4ca1-476a-ad2e-eb1a9b6e845c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('vec', None), ('logr', LogisticRegression())],\n",
       " 'verbose': False,\n",
       " 'vec': None,\n",
       " 'logr': LogisticRegression(),\n",
       " 'logr__C': 1.0,\n",
       " 'logr__class_weight': None,\n",
       " 'logr__dual': False,\n",
       " 'logr__fit_intercept': True,\n",
       " 'logr__intercept_scaling': 1,\n",
       " 'logr__l1_ratio': None,\n",
       " 'logr__max_iter': 100,\n",
       " 'logr__multi_class': 'auto',\n",
       " 'logr__n_jobs': None,\n",
       " 'logr__penalty': 'l2',\n",
       " 'logr__random_state': None,\n",
       " 'logr__solver': 'lbfgs',\n",
       " 'logr__tol': 0.0001,\n",
       " 'logr__verbose': 0,\n",
       " 'logr__warm_start': False}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_log.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8651210b-a80f-4be8-ba91-1fd0d3b41b6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('cvec', CountVectorizer())],\n",
       " 'verbose': False,\n",
       " 'cvec': CountVectorizer(),\n",
       " 'cvec__analyzer': 'word',\n",
       " 'cvec__binary': False,\n",
       " 'cvec__decode_error': 'strict',\n",
       " 'cvec__dtype': numpy.int64,\n",
       " 'cvec__encoding': 'utf-8',\n",
       " 'cvec__input': 'content',\n",
       " 'cvec__lowercase': True,\n",
       " 'cvec__max_df': 1.0,\n",
       " 'cvec__max_features': None,\n",
       " 'cvec__min_df': 1,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'cvec__preprocessor': None,\n",
       " 'cvec__stop_words': None,\n",
       " 'cvec__strip_accents': None,\n",
       " 'cvec__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'cvec__tokenizer': None,\n",
       " 'cvec__vocabulary': None}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at params for CVEC\n",
    "cvec_params = Pipeline([('cvec', CountVectorizer())])\n",
    "cvec_params.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "646fb7f7-cb35-4bcd-92e5-dc854cb6f38d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('tvec', TfidfVectorizer())],\n",
       " 'verbose': False,\n",
       " 'tvec': TfidfVectorizer(),\n",
       " 'tvec__analyzer': 'word',\n",
       " 'tvec__binary': False,\n",
       " 'tvec__decode_error': 'strict',\n",
       " 'tvec__dtype': numpy.float64,\n",
       " 'tvec__encoding': 'utf-8',\n",
       " 'tvec__input': 'content',\n",
       " 'tvec__lowercase': True,\n",
       " 'tvec__max_df': 1.0,\n",
       " 'tvec__max_features': None,\n",
       " 'tvec__min_df': 1,\n",
       " 'tvec__ngram_range': (1, 1),\n",
       " 'tvec__norm': 'l2',\n",
       " 'tvec__preprocessor': None,\n",
       " 'tvec__smooth_idf': True,\n",
       " 'tvec__stop_words': None,\n",
       " 'tvec__strip_accents': None,\n",
       " 'tvec__sublinear_tf': False,\n",
       " 'tvec__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'tvec__tokenizer': None,\n",
       " 'tvec__use_idf': True,\n",
       " 'tvec__vocabulary': None}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at params for TVEC\n",
    "tvec_params = Pipeline([('tvec', TfidfVectorizer())])\n",
    "tvec_params.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8031fe48-26a9-4a51-86a2-628ea816a33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pgrid =[\n",
    "    {\n",
    "    'vec': [CountVectorizer()],\n",
    "    'cvec__stop_words': [None, 'english'],\n",
    "    'cvec__max_features': [100, 200, 300], \n",
    "    'cvec__preprocessor': [None, lemmatize_txt, stem_txt]\n",
    "    },\n",
    "    {\n",
    "    'vec': [TfidfVectorizer()],\n",
    "    'tvec__stop_words': [None, 'english'],\n",
    "    'tvec__max_features': [100, 200, 300], \n",
    "    'tvec__preprocessor': [None, lemmatize_txt, stem_txt]\n",
    "    },\n",
    "    {\n",
    "    'logr__C': [np.linspace(.01,3,5)],\n",
    "    'logr__penalty': ['l1', 'l2']\n",
    "    }\n",
    "]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6860c504-ddd7-40a3-9bdd-130f8346e4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gs = GridSearchCV(pipe_log, pgrid, cv=5)\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64eb2664-3048-4790-8856-611709c7b510",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train:', gs.score(X_train, y_train))\n",
    "print('Test:', gs.score(X_test, y_test))\n",
    "print('Best Params: ', gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1492eba3-571e-4625-b82b-bb8acd8f963a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
